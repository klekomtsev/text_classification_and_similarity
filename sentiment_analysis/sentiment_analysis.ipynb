{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"sentiment_analysis.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kbMxSceU1XGe","colab_type":"text"},"source":["# Sentiment classification. IMDb dataset."]},{"cell_type":"code","metadata":{"id":"eyFW8WeBQ7zt","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import gensim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RamfrDWXQ70B","colab_type":"code","outputId":"5f71d0d0-ba9f-4858-f657-634c0c90e7c5","executionInfo":{"status":"ok","timestamp":1583206002512,"user_tz":480,"elapsed":219,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YnjtKfR6RTA_","colab_type":"code","outputId":"81c436b8-c80c-49d5-ce41-a9329d4feec1","executionInfo":{"status":"ok","timestamp":1583206002948,"user_tz":480,"elapsed":128,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SK3iHi6IQ70Q","colab_type":"code","outputId":"1eb4f7ec-7803-473d-bf41-2e98ba9cb615","executionInfo":{"status":"ok","timestamp":1583206011235,"user_tz":480,"elapsed":958,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/capstone2/sentiment_analysis/imdb_dataset.csv', encoding='utf-8')\n","df.head(3)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"bpIX3g4_xaOa","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","# Create a label (category) encoder object\n","le = preprocessing.LabelEncoder()\n","# Fit the encoder to the pandas column\n","le.fit(df['sentiment'])\n","# Apply the fitted encoder to the pandas column\n","df['sentiment'] = le.transform(df['sentiment']) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5H9X5dEyiFm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"outputId":"f04f5824-a01e-49cb-df72-1e085189ed6e","executionInfo":{"status":"ok","timestamp":1583206021360,"user_tz":480,"elapsed":239,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}}},"source":["df.head(3)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  One of the other reviewers has mentioned that ...          1\n","1  A wonderful little production. <br /><br />The...          1\n","2  I thought this was a wonderful way to spend ti...          1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"iFsmYhPeQ70n","colab_type":"text"},"source":["# Preprocess dataset."]},{"cell_type":"code","metadata":{"id":"qSCc4NwQxo3N","colab_type":"code","outputId":"6d07f973-3791-477e-e191-1393b69f3fbd","executionInfo":{"status":"ok","timestamp":1583206027382,"user_tz":480,"elapsed":546,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import string\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import re\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def preprocessor(text):\n","    '''Preprocessor function to tokenize, \n","    remove the markup and join back to a string. '''\n","\n","    ## Remove HTML markup and standardize emotion characters\n","    #text = re.sub('<[^>]*>', '', text)\n","    #emotions = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n","    #                       text)\n","    #text = (re.sub('[\\W]+', ' ', text.lower()) +\n","    #        ' '.join(emotions).replace('-', ''))\n","    \n","    # tokenize\n","    tokens = word_tokenize(text)\n","    \n","    # convert to lower case\n","    tokens = [w.lower() for w in tokens]\n","    \n","    # remove punctutation from each word\n","    table = str.maketrans('', '', string.punctuation)\n","    stripped = [w.translate(table) for w in tokens]\n","    \n","    # remove non-alphabetic tokens\n","    words = [word for word in stripped if word.isalpha()]\n","    \n","    # remove stop words\n","    stop_words = stopwords.words('english')\n","    words = [w for w in words if w not in stop_words]\n","    \n","    # join back to a string\n","    seperator = ' '\n","    text = seperator.join([w for w in words])\n","    return text"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FNgotmswQ70y","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(preprocessor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoirIqfyQ703","colab_type":"code","outputId":"45470990-eb29-4763-e932-7abfdf723cde","executionInfo":{"status":"ok","timestamp":1583206139262,"user_tz":480,"elapsed":109448,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":352}},"source":["df.head(10)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one reviewers mentioned watching oz episode ho...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wonderful little production br br filming tech...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>thought wonderful way spend time hot summer we...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>basically family little boy jake thinks zombie...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>petter mattei love time money visually stunnin...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>probably alltime favorite movie story selfless...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>sure would like see resurrection dated seahunt...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>show amazing fresh innovative idea first aired...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>encouraged positive comments film looking forw...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>like original gut wrenching laughter like movi...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  one reviewers mentioned watching oz episode ho...          1\n","1  wonderful little production br br filming tech...          1\n","2  thought wonderful way spend time hot summer we...          1\n","3  basically family little boy jake thinks zombie...          0\n","4  petter mattei love time money visually stunnin...          1\n","5  probably alltime favorite movie story selfless...          1\n","6  sure would like see resurrection dated seahunt...          1\n","7  show amazing fresh innovative idea first aired...          0\n","8  encouraged positive comments film looking forw...          0\n","9  like original gut wrenching laughter like movi...          1"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"LbssfsIq-_DC","colab_type":"text"},"source":["# Word2Vec model"]},{"cell_type":"code","metadata":{"id":"J7cUzWqfncp-","colab_type":"code","colab":{}},"source":["def w2v_input(column):\n","    reviews = list()\n","\n","    for index, row in df.iterrows():\n","        reviews.append(gensim.utils.simple_preprocess(row[column]))\n","    \n","    return reviews"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJIcILh086AO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"outputId":"42383eb0-06b5-430e-b023-f0edbbfe1fbb","executionInfo":{"status":"ok","timestamp":1583206618703,"user_tz":480,"elapsed":29934,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}}},"source":["reviews = w2v_input('review')\n","# build vocabulary and train model\n","w2v_model = gensim.models.Word2Vec(reviews,\n","                                   size=150,\n","                                   window=10,\n","                                   min_count=2, \n","                                   workers=-1)\n","    \n","w2v_model.train(reviews, total_examples=len(reviews), epochs=100)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 0)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"R32qKBih-UPg","colab_type":"code","outputId":"d31d2908-3409-4b15-9c6b-79129fc8c8b8","executionInfo":{"status":"ok","timestamp":1583206618704,"user_tz":480,"elapsed":28782,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["# vocabulary size\n","w2v_vocabulary = list(w2v_model.wv.vocab)\n","print('Vocabulary size is: %d' %len(w2v_vocabulary))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Vocabulary size is: 67899\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xXE7fL44_C-1","colab_type":"code","outputId":"c00efb8f-85c1-450e-b8c9-6e182eb27ff5","executionInfo":{"status":"ok","timestamp":1583206618705,"user_tz":480,"elapsed":20342,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":234}},"source":["w2v_model.wv.most_similar('sad')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('homeier', 0.34255775809288025),\n"," ('reworking', 0.32878434658050537),\n"," ('goneril', 0.3280695080757141),\n"," ('bluto', 0.3236783444881439),\n"," ('erie', 0.31672319769859314),\n"," ('idling', 0.31376826763153076),\n"," ('fastidious', 0.30772221088409424),\n"," ('proclaim', 0.29738378524780273),\n"," ('martialarts', 0.2972051203250885),\n"," ('fudges', 0.29405030608177185)]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"wSLFpU8h8OAZ","colab_type":"code","outputId":"677f4581-d0d4-4240-f674-0d745cc26654","executionInfo":{"status":"ok","timestamp":1583206706829,"user_tz":480,"elapsed":227,"user":{"displayName":"Konstantin Lekomtsev","photoUrl":"","userId":"02021487482276961340"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["w2v_model.wv.doesnt_match('woman king queen movie'.split())"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'movie'"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"eo3XLNHYQ71J","colab_type":"text"},"source":["# Create a dataset."]},{"cell_type":"code","metadata":{"id":"E4TrNFtfQ71L","colab_type":"code","colab":{}},"source":["target = df.pop('sentiment')\n","\n","ds_raw = tf.data.Dataset.from_tensor_slices(\n","    (df.values, target.values))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHn6JeLcQ71Q","colab_type":"code","colab":{}},"source":["# Inspect:\n","for entry in ds_raw.take(3):\n","    tf.print(entry[0].numpy()[0][:50], entry[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pR85d6OGQ71U","colab_type":"text"},"source":["# Train / validation / test split. "]},{"cell_type":"code","metadata":{"id":"6DutMo7KQ71V","colab_type":"code","colab":{}},"source":["tf.random.set_seed(1)\n","\n","ds_raw = ds_raw.shuffle(\n","    50000, reshuffle_each_iteration=False)\n","\n","ds_raw_test = ds_raw.take(25000)\n","ds_raw_train_valid = ds_raw.skip(25000)\n","ds_raw_train = ds_raw_train_valid.take(20000)\n","ds_raw_valid = ds_raw_train_valid.skip(20000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTVnm8JUaQ5D","colab_type":"text"},"source":["# Find unique tokens."]},{"cell_type":"code","metadata":{"id":"12m60B1uQ71Y","colab_type":"code","colab":{}},"source":["from collections import Counter\n","import tensorflow_datasets as tfds\n","\n","tokenizer = tfds.features.text.Tokenizer()\n","token_counts = Counter()\n","\n","for example in ds_raw_train:\n","    tokens = tokenizer.tokenize(example[0].numpy()[0])\n","    token_counts.update(tokens)\n","    \n","print('Vocab-size:', len(token_counts))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wn7zKLwUck9m","colab_type":"text"},"source":["# Encoding each unique token into integers."]},{"cell_type":"code","metadata":{"id":"tkmL-bnKcJo8","colab_type":"code","colab":{}},"source":["encoder = tfds.features.text.TokenTextEncoder(token_counts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"emSW_n1jc8_a","colab_type":"code","colab":{}},"source":["example_str = 'read watch although'\n","encoder.encode(example_str)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k4Pq2WKodojE","colab_type":"text"},"source":["# Define the function for transformation."]},{"cell_type":"code","metadata":{"id":"xmc4RFoYdnxF","colab_type":"code","colab":{}},"source":["def encode(text_tensor, label):\n","    text = text_tensor.numpy()[0]\n","    encoded_text = encoder.encode(text)\n","    return encoded_text, label\n","\n","# Wrap the encode function to a TensorFlow operator\n","def encode_map_fn(text, label):\n","    return tf.py_function(encode, inp=[text, label], \n","                          Tout=(tf.int64, tf.int64))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M78kFXiQcu2Q","colab_type":"code","colab":{}},"source":["ds_train = ds_raw_train.map(encode_map_fn)\n","ds_valid = ds_raw_valid.map(encode_map_fn)\n","ds_test = ds_raw_test.map(encode_map_fn)\n","\n","tf.random.set_seed(1)\n","for example in ds_train.shuffle(1000).take(5):\n","    print('Sequence length:', example[0].shape)\n","    \n","example"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P5VE7ia9ermW","colab_type":"text"},"source":["# Batching the dataset."]},{"cell_type":"code","metadata":{"id":"FKGly-Rwdz29","colab_type":"code","colab":{}},"source":["train_data = ds_train.padded_batch(\n","    32, padded_shapes=([-1],[]))\n","\n","valid_data = ds_valid.padded_batch(\n","    32, padded_shapes=([-1],[]))\n","\n","test_data = ds_test.padded_batch(\n","    32, padded_shapes=([-1],[]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWBp2i7fizU8","colab_type":"text"},"source":["# RNN model."]},{"cell_type":"code","metadata":{"id":"1QDCtdS-e2IB","colab_type":"code","colab":{}},"source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import SimpleRNN\n","from tensorflow.keras.layers import Dense\n","\n","embedding_dim = 20\n","vocab_size = len(token_counts) + 2\n","\n","tf.random.set_seed(1)\n","\n","# build the model\n","bi_lstm_model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=vocab_size,\n","                              output_dim=embedding_dim),\n","    tf.keras.layers.Dense(20,\n","                          input_shape=(embedding_dim,)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Bidirectional(\n","        tf.keras.layers.LSTM(20, \n","                             return_sequences=False)),\n","    tf.keras.layers.Dense(2, \n","                          activation='softmax')\n","])\n","\n","bi_lstm_model.summary()\n","\n","# compile and train:\n","bi_lstm_model.compile(optimizer='adam',\n","                      loss='sparse_categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","history = bi_lstm_model.fit(train_data, \n","                            validation_data=valid_data, \n","                            epochs=6)\n","\n","# evaluate on the test data:\n","test_results= bi_lstm_model.evaluate(test_data)\n","print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQPupmRcfRsi","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","def plot_train_valid(model_history):\n","    hist = model_history.history\n","    x_arr = np.arange(len(hist['loss'])) + 1\n","\n","    fig = plt.figure(figsize=(12, 4))\n","    ax = fig.add_subplot(1, 2, 1)\n","    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n","    ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\n","    ax.legend(fontsize=15)\n","    ax.set_xlabel('Epoch', size=15)\n","    ax.set_ylabel('Loss', size=15)\n","\n","    ax = fig.add_subplot(1, 2, 2)\n","    ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n","    ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\n","    ax.legend(fontsize=15)\n","    ax.set_xlabel('Epoch', size=15)\n","    ax.set_ylabel('Accuracy', size=15)\n","\n","    return plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aK8UNT1CiXLV","colab_type":"code","colab":{}},"source":["plot_train_valid(history)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Guh-aysqigTu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}