{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import functools\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_and_confusion_report(actual_label,predicted_label,threshold):\n",
    "    predicted_label = np.where(predicted_label>threshold,1,0)\n",
    "    report=classification_report(actual_label,predicted_label)\n",
    "    cm = confusion_matrix(actual_label,predicted_label)\n",
    "    print(cm)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_keras_metric(method):\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH=20   #The sentence length varies from 0 to 125 in question 1 and 0 to 237 in question2\n",
    "                         #and the average word length is 11\n",
    "nb_words = 5000          #The word index length is 80904\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "auc_roc = as_keras_metric(tf.metrics.auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\\\coviam bangalore\\\\all\\\\train.csv\")\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the matching words and characters in the two sets of questions.\n",
    "#Jaccard Similarity\n",
    "\n",
    "def match_count(q1,q2):\n",
    "    set_1 = set(q1)\n",
    "    set_2 = set(q2)\n",
    "    set_3 = set_1.intersection(set_2)\n",
    "    return len(set_3)/(len(set_1)+len(set_2)-len(set_3))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.question1 = data.question1.str.lower()\n",
    "data.question2 = data.question2.str.lower()\n",
    "data_obj = data.select_dtypes(['object'])  #selects the columns question1 and question2\n",
    "data[\"char_match_count\"]= data.apply(lambda row: match_count(row[\"question1\"],row[\"question2\"]),axis=1)\n",
    "data[\"word_match_count\"] = data.apply(lambda row: match_count(row[\"question1\"].split(),row[\"question2\"].split()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.000000\n",
      "1    0.703704\n",
      "2    0.750000\n",
      "3    0.466667\n",
      "4    0.653846\n",
      "Name: char_match_count, dtype: float64\n",
      "0    0.769231\n",
      "1    0.250000\n",
      "2    0.200000\n",
      "3    0.000000\n",
      "4    0.111111\n",
      "Name: word_match_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"char_match_count\"].head(5))\n",
    "print(data[\"word_match_count\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17597747320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.question1.str.len().value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what is the step by step guide to invest in sh...\n",
       "1    what is the story of kohinoor (koh-i-noor) dia...\n",
       "2    how can i increase the speed of my internet co...\n",
       "3    why am i mentally very lonely? how can i solve...\n",
       "4    which one dissolve in water quikly sugar, salt...\n",
       "Name: question1, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.question1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cosine_similarity\"]=data.apply(lambda x: get_cosine(text_to_vector(x[\"question1\"]),text_to_vector(x[\"question2\"])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>char_match_count</th>\n",
       "      <th>word_match_count</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.944911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.613572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.338062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely? how can i solve...</td>\n",
       "      <td>find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.419314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>astrology: i am a capricorn sun cap moon and c...</td>\n",
       "      <td>i'm a triple capricorn (sun, moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>should i buy tiago?</td>\n",
       "      <td>what keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>how can i be a good geologist?</td>\n",
       "      <td>what should i do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>when do you use シ instead of し?</td>\n",
       "      <td>when do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.801784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>motorola (company): can i hack my charter moto...</td>\n",
       "      <td>how do i hack motorola dcx3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>method to find separation of slits using fresn...</td>\n",
       "      <td>what are some of the things technicians can te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>how do i read and find my youtube comments?</td>\n",
       "      <td>how can i see all my youtube comments?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>what can make physics easy to learn?</td>\n",
       "      <td>how can you make physics easy to learn?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.801784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>what was your first sexual experience like?</td>\n",
       "      <td>what was your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.925820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>what are the laws to change your status from a...</td>\n",
       "      <td>what are the laws to change your status from a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>what would a trump presidency mean for current...</td>\n",
       "      <td>how will a trump presidency affect the student...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>what does manipulation mean?</td>\n",
       "      <td>what does manipulation means?</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>why do girls want to be friends with the guy t...</td>\n",
       "      <td>how do guys feel after rejecting a girl?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.102062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>why are so many quora users posting questions ...</td>\n",
       "      <td>why do people ask quora questions which can be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.346688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>which is the best digital marketing institutio...</td>\n",
       "      <td>which is the best digital marketing institute ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>why do rockets look white?</td>\n",
       "      <td>why are rockets and boosters painted white?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.507093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>what's causing someone to be jealous?</td>\n",
       "      <td>what can i do to avoid being jealous of someone?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.478091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>what are the questions should not ask on quora?</td>\n",
       "      <td>which question should i ask on quora?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>how much is 30 kv in hp?</td>\n",
       "      <td>where can i find a conversion chart for cc to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>what does it mean that every time i look at th...</td>\n",
       "      <td>how many times a day do a clock’s hands overlap?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>what are some tips on making it through the jo...</td>\n",
       "      <td>what are some tips on making it through the jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.897085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>what is web application?</td>\n",
       "      <td>what is the web application framework?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>does society place too much importance on sports?</td>\n",
       "      <td>how do sports contribute to the society?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>what is best way to make money online?</td>\n",
       "      <td>what is best way to ask for money online?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.824958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>how should i prepare for ca final law?</td>\n",
       "      <td>how one should know that he/she completely pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.588348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>what's one thing you would like to do better?</td>\n",
       "      <td>what's one thing you do despite knowing better?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.737865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>what are some special cares for someone with a...</td>\n",
       "      <td>how can i keep my nose from getting stuffy at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.226134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>what game of thrones villain would be the most...</td>\n",
       "      <td>what game of thrones villain would you most li...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.842665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>does the united states government still blackl...</td>\n",
       "      <td>how is the average speed of gas molecules dete...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.072739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>what is the best travel website in spain?</td>\n",
       "      <td>what is the best travel website?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>why do some people think obama will try to tak...</td>\n",
       "      <td>has there been a gun control initiative to tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.370625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>i'm a 19-year-old. how can i improve my skills...</td>\n",
       "      <td>i am a 19 year old guy. how can i become a bil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.678401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>when a girlfriend asks her boyfriend \"why did ...</td>\n",
       "      <td>my girlfriend said that we should end this bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.335830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>how do we prepare for upsc?</td>\n",
       "      <td>how do i prepare for civil service?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.617213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>what is the stall speed and aoa of an f-14 wit...</td>\n",
       "      <td>why did aircraft stop using variable-sweep win...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.267261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>why do slavs squat?</td>\n",
       "      <td>will squats make my legs thicker?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>when can i expect my cognizant confirmation mail?</td>\n",
       "      <td>when can i expect cognizant confirmation mail?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.935414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>can i make 50,000 a month by day trading?</td>\n",
       "      <td>can i make 30,000 a month by day trading?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>is being a good kid and not being a rebel wort...</td>\n",
       "      <td>is being bored good for a kid?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.591608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>what universities does rexnord recruit new gra...</td>\n",
       "      <td>what universities does b&amp;g foods recruit new g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.883883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>what is the quickest way to increase instagram...</td>\n",
       "      <td>how can we increase our number of instagram fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>how did darth vader fought darth maul in star ...</td>\n",
       "      <td>does quora have a character limit for profile ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>what are the stages of breaking up between cou...</td>\n",
       "      <td>who is affected more by a breakup, the boy or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.283473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>what are some examples of products that can be...</td>\n",
       "      <td>what are some of the products made from crude ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.701646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>how do i make friends.</td>\n",
       "      <td>how to make friends ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "0    0     1     2  what is the step by step guide to invest in sh...   \n",
       "1    1     3     4  what is the story of kohinoor (koh-i-noor) dia...   \n",
       "2    2     5     6  how can i increase the speed of my internet co...   \n",
       "3    3     7     8  why am i mentally very lonely? how can i solve...   \n",
       "4    4     9    10  which one dissolve in water quikly sugar, salt...   \n",
       "5    5    11    12  astrology: i am a capricorn sun cap moon and c...   \n",
       "6    6    13    14                                should i buy tiago?   \n",
       "7    7    15    16                     how can i be a good geologist?   \n",
       "8    8    17    18                    when do you use シ instead of し?   \n",
       "9    9    19    20  motorola (company): can i hack my charter moto...   \n",
       "10  10    21    22  method to find separation of slits using fresn...   \n",
       "11  11    23    24        how do i read and find my youtube comments?   \n",
       "12  12    25    26               what can make physics easy to learn?   \n",
       "13  13    27    28        what was your first sexual experience like?   \n",
       "14  14    29    30  what are the laws to change your status from a...   \n",
       "15  15    31    32  what would a trump presidency mean for current...   \n",
       "16  16    33    34                       what does manipulation mean?   \n",
       "17  17    35    36  why do girls want to be friends with the guy t...   \n",
       "18  18    37    38  why are so many quora users posting questions ...   \n",
       "19  19    39    40  which is the best digital marketing institutio...   \n",
       "20  20    41    42                         why do rockets look white?   \n",
       "21  21    43    44              what's causing someone to be jealous?   \n",
       "22  22    45    46    what are the questions should not ask on quora?   \n",
       "23  23    47    48                           how much is 30 kv in hp?   \n",
       "24  24    49    50  what does it mean that every time i look at th...   \n",
       "25  25    51    52  what are some tips on making it through the jo...   \n",
       "26  26    53    54                           what is web application?   \n",
       "27  27    55    56  does society place too much importance on sports?   \n",
       "28  28    57    58             what is best way to make money online?   \n",
       "29  29    59    60             how should i prepare for ca final law?   \n",
       "30  30    61    62      what's one thing you would like to do better?   \n",
       "31  31    63    64  what are some special cares for someone with a...   \n",
       "32  32    65    66  what game of thrones villain would be the most...   \n",
       "33  33    67    68  does the united states government still blackl...   \n",
       "34  34    69    70          what is the best travel website in spain?   \n",
       "35  35    71    72  why do some people think obama will try to tak...   \n",
       "36  36    73    74  i'm a 19-year-old. how can i improve my skills...   \n",
       "37  37    75    76  when a girlfriend asks her boyfriend \"why did ...   \n",
       "38  38    77    78                        how do we prepare for upsc?   \n",
       "39  39    79    80  what is the stall speed and aoa of an f-14 wit...   \n",
       "40  40    81    82                                why do slavs squat?   \n",
       "41  41    83    84  when can i expect my cognizant confirmation mail?   \n",
       "42  42    85    86          can i make 50,000 a month by day trading?   \n",
       "43  43    87    88  is being a good kid and not being a rebel wort...   \n",
       "44  44    89    90  what universities does rexnord recruit new gra...   \n",
       "45  45    91    92  what is the quickest way to increase instagram...   \n",
       "46  46    93    94  how did darth vader fought darth maul in star ...   \n",
       "47  47    95    96  what are the stages of breaking up between cou...   \n",
       "48  48    97    98  what are some examples of products that can be...   \n",
       "49  49    99   100                             how do i make friends.   \n",
       "\n",
       "                                            question2  is_duplicate  \\\n",
       "0   what is the step by step guide to invest in sh...             0   \n",
       "1   what would happen if the indian government sto...             0   \n",
       "2   how can internet speed be increased by hacking...             0   \n",
       "3   find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4             which fish would survive in salt water?             0   \n",
       "5   i'm a triple capricorn (sun, moon and ascendan...             1   \n",
       "6   what keeps childern active and far from phone ...             0   \n",
       "7           what should i do to be a great geologist?             1   \n",
       "8               when do you use \"&\" instead of \"and\"?             0   \n",
       "9   how do i hack motorola dcx3400 for free internet?             0   \n",
       "10  what are some of the things technicians can te...             0   \n",
       "11             how can i see all my youtube comments?             1   \n",
       "12            how can you make physics easy to learn?             1   \n",
       "13             what was your first sexual experience?             1   \n",
       "14  what are the laws to change your status from a...             0   \n",
       "15  how will a trump presidency affect the student...             1   \n",
       "16                      what does manipulation means?             1   \n",
       "17           how do guys feel after rejecting a girl?             0   \n",
       "18  why do people ask quora questions which can be...             1   \n",
       "19  which is the best digital marketing institute ...             0   \n",
       "20        why are rockets and boosters painted white?             1   \n",
       "21   what can i do to avoid being jealous of someone?             0   \n",
       "22              which question should i ask on quora?             0   \n",
       "23  where can i find a conversion chart for cc to ...             0   \n",
       "24   how many times a day do a clock’s hands overlap?             0   \n",
       "25  what are some tips on making it through the jo...             0   \n",
       "26             what is the web application framework?             0   \n",
       "27           how do sports contribute to the society?             0   \n",
       "28          what is best way to ask for money online?             0   \n",
       "29  how one should know that he/she completely pre...             1   \n",
       "30    what's one thing you do despite knowing better?             0   \n",
       "31  how can i keep my nose from getting stuffy at ...             1   \n",
       "32  what game of thrones villain would you most li...             1   \n",
       "33  how is the average speed of gas molecules dete...             0   \n",
       "34                   what is the best travel website?             0   \n",
       "35  has there been a gun control initiative to tak...             0   \n",
       "36  i am a 19 year old guy. how can i become a bil...             0   \n",
       "37  my girlfriend said that we should end this bec...             0   \n",
       "38                how do i prepare for civil service?             1   \n",
       "39  why did aircraft stop using variable-sweep win...             0   \n",
       "40                  will squats make my legs thicker?             0   \n",
       "41     when can i expect cognizant confirmation mail?             0   \n",
       "42          can i make 30,000 a month by day trading?             0   \n",
       "43                     is being bored good for a kid?             0   \n",
       "44  what universities does b&g foods recruit new g...             0   \n",
       "45  how can we increase our number of instagram fo...             0   \n",
       "46  does quora have a character limit for profile ...             0   \n",
       "47  who is affected more by a breakup, the boy or ...             0   \n",
       "48  what are some of the products made from crude ...             1   \n",
       "49                              how to make friends ?             1   \n",
       "\n",
       "    char_match_count  word_match_count  cosine_similarity  \n",
       "0           1.000000          0.769231           0.944911  \n",
       "1           0.703704          0.250000           0.613572  \n",
       "2           0.750000          0.200000           0.338062  \n",
       "3           0.466667          0.000000           0.000000  \n",
       "4           0.653846          0.111111           0.419314  \n",
       "5           0.740741          0.347826           0.631579  \n",
       "6           0.458333          0.000000           0.000000  \n",
       "7           0.777778          0.333333           0.503953  \n",
       "8           0.789474          0.600000           0.801784  \n",
       "9           0.730769          0.200000           0.444444  \n",
       "10          0.863636          0.041667           0.133333  \n",
       "11          0.800000          0.416667           0.589256  \n",
       "12          0.947368          0.666667           0.801784  \n",
       "13          0.950000          0.625000           0.925820  \n",
       "14          0.916667          0.833333           0.978723  \n",
       "15          0.833333          0.148148           0.218218  \n",
       "16          1.000000          0.600000           0.750000  \n",
       "17          0.952381          0.052632           0.102062  \n",
       "18          0.826087          0.238095           0.346688  \n",
       "19          0.904762          0.636364           0.777778  \n",
       "20          0.736842          0.333333           0.507093  \n",
       "21          0.818182          0.066667           0.478091  \n",
       "22          0.944444          0.333333           0.503953  \n",
       "23          0.500000          0.000000           0.000000  \n",
       "24          0.826087          0.000000           0.057831  \n",
       "25          0.956522          0.812500           0.897085  \n",
       "26          0.789474          0.428571           0.816497  \n",
       "27          0.750000          0.000000           0.267261  \n",
       "28          0.888889          0.700000           0.824958  \n",
       "29          0.739130          0.428571           0.588348  \n",
       "30          0.904762          0.545455           0.737865  \n",
       "31          0.863636          0.125000           0.226134  \n",
       "32          1.000000          0.611111           0.842665  \n",
       "33          0.689655          0.043478           0.072739  \n",
       "34          0.866667          0.555556           0.866025  \n",
       "35          0.869565          0.173913           0.370625  \n",
       "36          0.741935          0.310345           0.678401  \n",
       "37          0.846154          0.083333           0.335830  \n",
       "38          0.764706          0.444444           0.617213  \n",
       "39          0.888889          0.038462           0.267261  \n",
       "40          0.523810          0.000000           0.000000  \n",
       "41          0.950000          0.875000           0.935414  \n",
       "42          0.904762          0.800000           0.900000  \n",
       "43          0.684211          0.235294           0.591608  \n",
       "44          0.884615          0.800000           0.883883  \n",
       "45          0.818182          0.200000           0.333333  \n",
       "46          0.772727          0.000000           0.000000  \n",
       "47          0.916667          0.107143           0.283473  \n",
       "48          0.818182          0.533333           0.701646  \n",
       "49          0.823529          0.250000           0.670820  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking only 20 as maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets split data here \n",
    "msk = np.random.rand(len(data)) < VALIDATION_SPLIT\n",
    "train = data[msk]\n",
    "test = data[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"cosine_similarity\"].head(5)\n",
    "type(train[\"cosine_similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train[['char_match_count','word_match_count','cosine_similarity']]\n",
    "test_features=test[['char_match_count','word_match_count','cosine_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'libr': 78094,\n",
       " 'infoobject': 69396,\n",
       " 'fraternity': 17127,\n",
       " \"upcounsel's\": 70555,\n",
       " 'phormictopus': 52088,\n",
       " 'perching': 61359,\n",
       " 'cp': 11158,\n",
       " 'abra': 92965,\n",
       " 'asi': 25590,\n",
       " 'echols': 84074,\n",
       " 'seraphim': 26143,\n",
       " 'stalingrad': 22953,\n",
       " 'planned': 5159,\n",
       " 'demultiplex': 61197,\n",
       " 'suspending': 27340,\n",
       " 'moleskin': 83036,\n",
       " 'bioreactor': 43078,\n",
       " 'unspeakable': 76953,\n",
       " 'advancements': 14279,\n",
       " 'y51': 82778,\n",
       " 'bhai': 27632,\n",
       " 'adjustments': 10842,\n",
       " 'diamomd': 65786,\n",
       " 'uvic': 95469,\n",
       " 'awesomeness': 30606,\n",
       " 'procrastination': 2705,\n",
       " 'plaid': 89107,\n",
       " 'pontians': 83541,\n",
       " 'motocross': 30893,\n",
       " 'escabar': 86035,\n",
       " 'chipset': 14691,\n",
       " 'trafic': 49337,\n",
       " 'flexion': 38330,\n",
       " 'murrieta': 50471,\n",
       " 'craziness': 30823,\n",
       " 'bearkup': 77868,\n",
       " 'flippingly': 57608,\n",
       " 'dervish': 67692,\n",
       " 'embed': 10784,\n",
       " 'characters': 1694,\n",
       " '65000': 25066,\n",
       " 'sturmabteilung': 36321,\n",
       " 'publix': 46450,\n",
       " 'demoralizing': 51495,\n",
       " 'converging': 26453,\n",
       " 'brotherels': 66835,\n",
       " 'sketchy': 65136,\n",
       " 'interpals': 78293,\n",
       " 'tpm': 33194,\n",
       " 'declaring': 9073,\n",
       " \"pakistan's\": 7736,\n",
       " 'rajiv': 14591,\n",
       " 'aligning': 37260,\n",
       " 'londonderry': 31680,\n",
       " 'scents': 27656,\n",
       " 'llm': 14874,\n",
       " 'omnitrix': 42911,\n",
       " \"pentagon's\": 80863,\n",
       " 'forefathers': 75416,\n",
       " \"'mainstream'\": 39671,\n",
       " 'homogenization': 82425,\n",
       " \"'give'\": 92649,\n",
       " 'karin': 37644,\n",
       " 'doing': 258,\n",
       " 'glued': 25951,\n",
       " 'orbit': 3500,\n",
       " 'circulating': 10679,\n",
       " 'esxi': 94454,\n",
       " 'pubescent': 56807,\n",
       " 'bootcamp': 8868,\n",
       " \"'apple'\": 53754,\n",
       " 'viva': 13787,\n",
       " 'comfortable': 3466,\n",
       " 'examination': 2522,\n",
       " 'raza': 70176,\n",
       " 'tiles': 2737,\n",
       " 'tmh': 55318,\n",
       " 'loaded': 11220,\n",
       " 'participant': 29850,\n",
       " 'jatagam': 67981,\n",
       " 'inpatient': 930,\n",
       " 'counter': 3393,\n",
       " 'ige': 36640,\n",
       " \"tsunade's\": 85003,\n",
       " 'ioe': 64647,\n",
       " 'cs101': 61003,\n",
       " 'ebookee': 87240,\n",
       " 'mittal': 36694,\n",
       " 'txt': 11207,\n",
       " 'foreign': 556,\n",
       " 'foundational': 34751,\n",
       " 'propane': 12102,\n",
       " 'philosophically': 29351,\n",
       " 'poseable': 83280,\n",
       " 'submit': 3244,\n",
       " 'educating': 22884,\n",
       " 'huge': 2128,\n",
       " 'borivali': 34802,\n",
       " 'management': 490,\n",
       " 'fugue': 27177,\n",
       " '3200': 28234,\n",
       " 'wring': 41406,\n",
       " 'mcconnell': 35322,\n",
       " \"kowalewicz's\": 72106,\n",
       " 'iiscian': 44172,\n",
       " 'genetic': 3773,\n",
       " 'futile': 45364,\n",
       " 'coas': 51610,\n",
       " 'mythological': 15291,\n",
       " 'instruments': 5146,\n",
       " 'frustration': 7711,\n",
       " 'benzoyl': 17993,\n",
       " 'prosecutor': 16714,\n",
       " '1809': 55544,\n",
       " 'cling': 28741,\n",
       " 'cuptask': 95321,\n",
       " 'florine': 70116,\n",
       " 'fillet': 37342,\n",
       " 'flotation': 86167,\n",
       " 'prudential': 30840,\n",
       " 'temaki': 87029,\n",
       " 'amasuite': 69817,\n",
       " 'claritin': 23161,\n",
       " \"'possession\": 58945,\n",
       " 'ln1': 68683,\n",
       " 'stdlib': 83369,\n",
       " 'gigabyte': 27768,\n",
       " 'indd': 36458,\n",
       " 'poto': 90579,\n",
       " \"guatemala's\": 21138,\n",
       " 'tiger': 4521,\n",
       " \"5'6\": 9014,\n",
       " '800k': 42286,\n",
       " 'soundtracks': 14566,\n",
       " 'arabic': 2900,\n",
       " '659': 61150,\n",
       " '820g': 40426,\n",
       " 'unusable': 37259,\n",
       " 'cooling': 7294,\n",
       " \"'couldn't've\": 37598,\n",
       " 'reassurance': 54845,\n",
       " 'remap': 55842,\n",
       " 'userid': 40119,\n",
       " \"csm's\": 94143,\n",
       " 'binocular': 29302,\n",
       " 'bicycling': 40185,\n",
       " 'unavoidably': 53359,\n",
       " \"'taarak\": 45461,\n",
       " 'khalli': 72775,\n",
       " 'ivp': 63593,\n",
       " 'harrington': 77008,\n",
       " 'unnatural': 13987,\n",
       " 'haridham': 76572,\n",
       " 'dumbos': 71567,\n",
       " 'paracrine': 63274,\n",
       " 'tamakam': 42756,\n",
       " 'uora': 83712,\n",
       " 'accomplish': 4443,\n",
       " 'haad': 76447,\n",
       " 'mysteriously': 31974,\n",
       " 'plugging': 25179,\n",
       " 'chabad': 59237,\n",
       " 'p3ht': 44169,\n",
       " 'mamke': 76970,\n",
       " 'pc3l': 32352,\n",
       " 'retailers': 6294,\n",
       " \"prithviraj's\": 64447,\n",
       " \"saarc's\": 39720,\n",
       " 'rules': 1907,\n",
       " 'lemniscus': 57492,\n",
       " 'wetting': 37303,\n",
       " 'broth': 19701,\n",
       " 'debridement': 86916,\n",
       " 'behave': 4915,\n",
       " 'mitochondrial': 30966,\n",
       " 'egghead': 75512,\n",
       " 'alibaba': 8934,\n",
       " 'optimisation': 25844,\n",
       " 'illegalise': 77466,\n",
       " 'karsi': 59822,\n",
       " 'scheweser': 62116,\n",
       " 'fugues': 46935,\n",
       " 'terrystips': 86347,\n",
       " '“core': 44446,\n",
       " \"6'2\": 21237,\n",
       " \"'rustom'\": 44925,\n",
       " 'cdna': 69282,\n",
       " 'manipulation': 11495,\n",
       " 'duplicated': 21441,\n",
       " 'headscarf': 29652,\n",
       " \"device'\": 51766,\n",
       " 'greil': 67184,\n",
       " 'sini': 84469,\n",
       " 'kombat': 17587,\n",
       " 'ba021ax': 63129,\n",
       " 'x√': 46675,\n",
       " 'dalhousie': 26485,\n",
       " 'whaff': 67362,\n",
       " 'tantriks': 60072,\n",
       " 'paracord': 50865,\n",
       " 'tsunade': 38316,\n",
       " 'homunculus': 78870,\n",
       " 'anyting': 51666,\n",
       " \"greenfield's\": 94070,\n",
       " 'tirumala': 17436,\n",
       " 'thumb': 9656,\n",
       " 'alignment': 15003,\n",
       " 'curtains': 25144,\n",
       " 'isolators': 94936,\n",
       " 'tuesdays': 38492,\n",
       " \"abraham's\": 52566,\n",
       " 'dreamt': 14341,\n",
       " 'irp': 49903,\n",
       " 'reheated': 32863,\n",
       " 'sinsadong': 90792,\n",
       " 'persue': 18226,\n",
       " '200kph': 82280,\n",
       " 'ghz': 4770,\n",
       " 'manufacturering': 75919,\n",
       " '£600': 52488,\n",
       " 'emoticon': 10234,\n",
       " 'threesome': 8121,\n",
       " 'declartion': 42465,\n",
       " 'intrigues': 71117,\n",
       " 'childless': 29992,\n",
       " 'hoaxed': 87842,\n",
       " \"'theta'\": 67256,\n",
       " 'aardvark': 94612,\n",
       " 'gloved': 87001,\n",
       " 'github': 3762,\n",
       " 'asme': 19725,\n",
       " 'pyloric': 73839,\n",
       " 'eurus': 54315,\n",
       " 'misspelling': 71012,\n",
       " 'sentora': 89169,\n",
       " 'stressors': 23721,\n",
       " 'haben': 91730,\n",
       " 'answers”': 94858,\n",
       " 'spokesperson': 43987,\n",
       " 'quicker': 10604,\n",
       " '2xweeks': 59777,\n",
       " 'difficulties？': 80937,\n",
       " 'heightened': 60641,\n",
       " \"'soft\": 58519,\n",
       " 'retires': 27369,\n",
       " \"'secular'\": 42769,\n",
       " 'tasha': 52227,\n",
       " 'banksters': 89462,\n",
       " 'hackers': 3725,\n",
       " 'professors': 2573,\n",
       " 'vocalic': 68331,\n",
       " 'horticulture': 28494,\n",
       " 'objections': 24633,\n",
       " 'azad': 11400,\n",
       " 'argus': 76279,\n",
       " 'intermarry': 49914,\n",
       " \"kentucky's\": 91602,\n",
       " 'tan80': 51895,\n",
       " 'artefacts': 54388,\n",
       " 'palladium': 26581,\n",
       " 'lard': 24176,\n",
       " 'updating': 10490,\n",
       " \"items'\": 91163,\n",
       " 'rs7': 77715,\n",
       " 'slapped': 14888,\n",
       " '2137tx': 81219,\n",
       " 'dimka': 93514,\n",
       " 'cordwainer': 69558,\n",
       " 'electors': 8569,\n",
       " 'ppo': 24255,\n",
       " 'nicobar': 17192,\n",
       " 'haki': 39098,\n",
       " 'gazing': 35307,\n",
       " 'god”': 50226,\n",
       " 'philippe': 37255,\n",
       " 'infragard': 67722,\n",
       " '1972': 16852,\n",
       " 'bittorrent': 15287,\n",
       " 'zopim': 42531,\n",
       " 'burrows': 39061,\n",
       " 'bia': 89425,\n",
       " 'argentinian': 49177,\n",
       " '50kg': 27503,\n",
       " 'rejecting': 11843,\n",
       " 'paramters': 88859,\n",
       " 'pension': 7215,\n",
       " 'gage”': 52146,\n",
       " 'colonial': 8247,\n",
       " 'companionship': 29037,\n",
       " 'helmholtz': 41323,\n",
       " 'h4': 9337,\n",
       " \"'cheater'\": 92464,\n",
       " 'caror': 57609,\n",
       " 'append': 33528,\n",
       " 'facetious': 29206,\n",
       " 'select': 3193,\n",
       " 'lopez': 15692,\n",
       " 'pmt': 19009,\n",
       " 'unemployment': 5728,\n",
       " 'eie': 25507,\n",
       " 'scrubs': 27434,\n",
       " 'windsurf': 49637,\n",
       " 'caricatures': 34376,\n",
       " 'english…us': 70048,\n",
       " 'wpl': 54554,\n",
       " 'dondokaya': 82930,\n",
       " 'ofdm': 70817,\n",
       " 'tastiest': 11028,\n",
       " 'very': 312,\n",
       " 'bowie’s': 95030,\n",
       " 'refile': 54247,\n",
       " 'viewpoint': 16796,\n",
       " 'hinjewadi': 42399,\n",
       " 'llms': 43095,\n",
       " 'dak': 92063,\n",
       " 'olds': 6181,\n",
       " 'sharing': 3073,\n",
       " 'life…': 57903,\n",
       " 'reformed': 13216,\n",
       " 'caliban': 47291,\n",
       " 'submental': 44760,\n",
       " \"py'\": 90270,\n",
       " 'participle': 12255,\n",
       " 'hypermesh': 23185,\n",
       " 'microwaveable': 58839,\n",
       " \"devil'\": 66731,\n",
       " \"juliet's\": 46699,\n",
       " \"behno'\": 77492,\n",
       " 'navac': 58934,\n",
       " 's7572': 86562,\n",
       " 'tbsp': 85767,\n",
       " 'kraken': 36347,\n",
       " 'shahabuddin': 50497,\n",
       " 'gor': 85907,\n",
       " 'concerts': 15610,\n",
       " 'prostar': 60007,\n",
       " 'buliding': 63625,\n",
       " '395': 35305,\n",
       " 'ferris': 21820,\n",
       " 'bangaluru': 34295,\n",
       " 'magnetosphere': 72731,\n",
       " 'salat': 47941,\n",
       " 'announcement': 6994,\n",
       " 'condense': 93808,\n",
       " 'flowing': 11459,\n",
       " 'cintas': 40563,\n",
       " 'spliff': 89413,\n",
       " 'yoo': 54613,\n",
       " 'msmed': 74188,\n",
       " 'la': 2558,\n",
       " 'fallback': 42663,\n",
       " 'somnolent': 93511,\n",
       " 'mastrubration': 60406,\n",
       " 'mangalyan': 83465,\n",
       " 'totka': 56049,\n",
       " 'nauru': 40412,\n",
       " 'endometritis': 44306,\n",
       " 'discoverability': 90326,\n",
       " 'ordinator': 92200,\n",
       " 'sooryavansham': 15503,\n",
       " 'complextion': 42076,\n",
       " \"'violent'\": 68662,\n",
       " 'teynampet': 59508,\n",
       " 'swarajathi': 67097,\n",
       " '667': 39538,\n",
       " 'prime…': 66178,\n",
       " 'kevin': 9686,\n",
       " '4b': 54181,\n",
       " \"con's\": 24199,\n",
       " \"todd's\": 81899,\n",
       " 'proxy': 4345,\n",
       " 'marsmus': 72830,\n",
       " 'troops': 6474,\n",
       " '56mm': 79291,\n",
       " 'mallesgwaram': 67931,\n",
       " 'answerbazzar': 71163,\n",
       " 'banstand': 75222,\n",
       " 'highgarden': 84495,\n",
       " 'sceneries': 69547,\n",
       " \"rowling's\": 20279,\n",
       " 'repelling': 40111,\n",
       " 'compenstated': 76407,\n",
       " 'deepens': 73603,\n",
       " \"'intolerance'\": 83663,\n",
       " 'collegium': 15734,\n",
       " 'zonbie': 71023,\n",
       " '33k': 52469,\n",
       " 'sue': 4358,\n",
       " 'easya': 49784,\n",
       " 'mew': 22933,\n",
       " 'coziness': 94958,\n",
       " 'benifts': 79605,\n",
       " 'situation': 1668,\n",
       " 'obscurial': 22627,\n",
       " 'muriatic': 39189,\n",
       " 'whist': 83918,\n",
       " 'wayfair’s': 92120,\n",
       " 'ratatouille': 47798,\n",
       " 'yearns': 49617,\n",
       " 'interbreeding': 71601,\n",
       " 'trance': 12243,\n",
       " 'may’s': 62899,\n",
       " 'mossack': 48975,\n",
       " 'bse': 7418,\n",
       " 'climates': 17450,\n",
       " 'rallied': 23997,\n",
       " \"species'\": 44818,\n",
       " 'sse': 17088,\n",
       " 'mems': 26596,\n",
       " '11b': 51859,\n",
       " 'rereading': 93742,\n",
       " 'harmfull': 25569,\n",
       " 'copyleft': 36362,\n",
       " 'comviva': 88237,\n",
       " 'codepen': 37764,\n",
       " 'outselling': 70064,\n",
       " 'vanaprastha': 56605,\n",
       " 'miscarry': 84024,\n",
       " 'fishing': 5914,\n",
       " 'sdram': 23667,\n",
       " 'delhis': 82676,\n",
       " 'memorization': 32092,\n",
       " 'rite': 28132,\n",
       " '125000': 76732,\n",
       " 'bioluminescence': 84681,\n",
       " 'b²': 71547,\n",
       " 'manlier': 43406,\n",
       " 'framify': 60125,\n",
       " 'offerings': 23462,\n",
       " 'directories': 16494,\n",
       " 'rationality': 18923,\n",
       " 'vidarbha': 32252,\n",
       " 'rejects': 9437,\n",
       " 'lakshadweep': 31146,\n",
       " 'frictionless': 20045,\n",
       " 'enamel': 18523,\n",
       " 'correcting': 21730,\n",
       " 'dictionary': 5064,\n",
       " 'creepiest': 4157,\n",
       " 'lashkar': 72051,\n",
       " '3n2': 65461,\n",
       " 'sabse': 80362,\n",
       " 'hlpful': 69900,\n",
       " 'productions': 21780,\n",
       " 'krispies': 57467,\n",
       " 'kapil': 4645,\n",
       " '251₹': 81416,\n",
       " 'denominated': 36080,\n",
       " 'input': 3136,\n",
       " 'sponsors': 7792,\n",
       " 'app’': 59604,\n",
       " 'beme': 44507,\n",
       " \"maharaj's\": 30048,\n",
       " 'flee': 20853,\n",
       " 'negetive': 56791,\n",
       " '367864744': 89785,\n",
       " 'totalitarian': 16109,\n",
       " 'ssdi': 33258,\n",
       " \"michigan's\": 36020,\n",
       " '777': 13427,\n",
       " '138th': 61445,\n",
       " 'dimed': 83678,\n",
       " 'discoloured': 68675,\n",
       " 'hat': 4817,\n",
       " 'revolvers': 33284,\n",
       " 'tromsø': 67297,\n",
       " 'deists': 25738,\n",
       " 'physician': 12415,\n",
       " 'hispanic': 12633,\n",
       " \"g'\": 35362,\n",
       " 'acedamics': 65765,\n",
       " 'welcomes': 51056,\n",
       " 'lingerie': 11965,\n",
       " \"tld's\": 73541,\n",
       " 'succeeds': 41935,\n",
       " 'storyline': 12865,\n",
       " 'dumpling': 42952,\n",
       " 'skycrapper': 85213,\n",
       " 'kaju': 67384,\n",
       " 'industory': 69934,\n",
       " 'chamfered': 94522,\n",
       " 'fcc': 26814,\n",
       " 'sandbox': 19739,\n",
       " 'lightroom': 19459,\n",
       " 'styrofoam': 19248,\n",
       " 'diphu': 53375,\n",
       " \"arts'\": 85474,\n",
       " 'spatter': 33276,\n",
       " 'girls': 307,\n",
       " 'began': 9431,\n",
       " 'raffle': 33404,\n",
       " 'tshirt': 19709,\n",
       " \"pulfrich's\": 68036,\n",
       " 'khosla': 32073,\n",
       " 'gazers': 89396,\n",
       " 'interferons': 58034,\n",
       " 'notaries': 53299,\n",
       " 'microevolution': 24852,\n",
       " '9703': 65771,\n",
       " '“river”': 92395,\n",
       " 'furinitue': 69326,\n",
       " 'convention': 6624,\n",
       " 'met': 1478,\n",
       " 'kaithi': 51749,\n",
       " 'glad': 28203,\n",
       " 'nayan': 70846,\n",
       " 'sutton': 62548,\n",
       " 'heir': 16928,\n",
       " \"'anticipate'\": 28663,\n",
       " 'yepme': 53059,\n",
       " 'ju': 23953,\n",
       " \"masrat's\": 84634,\n",
       " 'theism': 20032,\n",
       " 'universitys': 86816,\n",
       " 'reunify': 86545,\n",
       " 'fashionable': 14356,\n",
       " 'advisabe': 65289,\n",
       " 'simplilearn': 17617,\n",
       " 'dhl': 16609,\n",
       " 'xenomorph': 37746,\n",
       " \"'bibliophile'\": 45288,\n",
       " 'kar': 40467,\n",
       " 'venmo': 9824,\n",
       " '“vt': 37538,\n",
       " 'wheelie': 59856,\n",
       " 'rolls': 6890,\n",
       " 'robberies': 35392,\n",
       " 'laika': 66562,\n",
       " 'reiki': 17216,\n",
       " 'expatriates': 15837,\n",
       " 'neodymium': 87898,\n",
       " 'oolta': 43831,\n",
       " 'phileas': 42656,\n",
       " 'renewing': 29292,\n",
       " 'relaxing': 11518,\n",
       " 'calibration': 25967,\n",
       " 'sunrock': 36446,\n",
       " 'joaquin': 10747,\n",
       " 'zaarly': 44253,\n",
       " 'kdramas': 61468,\n",
       " 'humanitarian': 22877,\n",
       " 'andhrapradesh': 40442,\n",
       " 'astana': 37012,\n",
       " 'delhites': 38521,\n",
       " 'conditio': 78773,\n",
       " 'vitmee': 52260,\n",
       " '1…': 60869,\n",
       " 'demineralised': 93670,\n",
       " 'guiter': 88586,\n",
       " \"buyer's\": 86555,\n",
       " 'antartica': 36874,\n",
       " 'paywall': 38751,\n",
       " 'onal': 66607,\n",
       " 'venkitaramanan': 56072,\n",
       " 'marginalised': 55519,\n",
       " 'puggle': 71459,\n",
       " 'hinder': 15450,\n",
       " 'powerlifting': 31525,\n",
       " 'saridon': 55634,\n",
       " 'designations': 24247,\n",
       " \"raipur's\": 68002,\n",
       " \"'cell\": 48210,\n",
       " 'payouts': 29539,\n",
       " 'ps4': 2561,\n",
       " 'lies': 2940,\n",
       " 'fabrikation': 74338,\n",
       " '630': 27284,\n",
       " 'presidium': 81586,\n",
       " 'peeta': 46908,\n",
       " 'durbin': 89490,\n",
       " 'niobium': 31562,\n",
       " '264': 25588,\n",
       " 'hosted': 8848,\n",
       " 'dawn': 8375,\n",
       " 'realities': 17503,\n",
       " 'quantum': 1654,\n",
       " \"''oops\": 84978,\n",
       " 'ovary': 21958,\n",
       " 'dart': 18868,\n",
       " 'candesarten': 51149,\n",
       " 'zach': 54343,\n",
       " 'wobbling': 53389,\n",
       " 'pcsj': 81602,\n",
       " 'gynecologist': 17749,\n",
       " 'punk': 14273,\n",
       " 'console': 3720,\n",
       " 'capsized': 39904,\n",
       " 'overtone': 89294,\n",
       " 'prepuce': 74160,\n",
       " \"pauli's\": 89702,\n",
       " 'peristaltic': 36636,\n",
       " 'fake': 953,\n",
       " 'nudist': 21435,\n",
       " 'dehumanize': 46668,\n",
       " 'tanmoy': 70919,\n",
       " 'dep': 58689,\n",
       " 'romana': 34390,\n",
       " 'ytube': 61537,\n",
       " 'layover': 8992,\n",
       " 'comprehending': 62659,\n",
       " 'repeatable': 76368,\n",
       " 'confide': 34767,\n",
       " 'remi': 73103,\n",
       " 'yang': 21589,\n",
       " 'twelvth': 57188,\n",
       " 'nate': 26999,\n",
       " 'λ': 39650,\n",
       " 'donnie': 22775,\n",
       " 'goveronment': 86913,\n",
       " 'diebold': 47003,\n",
       " 'pzt': 86424,\n",
       " 'reincarnates': 36295,\n",
       " \"obama's\": 4333,\n",
       " 'panhandler': 62797,\n",
       " \"'granny's\": 35914,\n",
       " 'malls': 11168,\n",
       " 'diabetic': 9500,\n",
       " 'unrecognizable': 74003,\n",
       " 'stepped': 16259,\n",
       " 'gerund': 21577,\n",
       " 'boxer': 5031,\n",
       " 'jhene': 92292,\n",
       " 'curcumin': 47653,\n",
       " 'fruits': 3407,\n",
       " 'worry': 3814,\n",
       " 'mikkelsen': 60261,\n",
       " 'unnecessary': 12291,\n",
       " 'endergonic': 40504,\n",
       " 'about…': 71357,\n",
       " 'nmn': 56749,\n",
       " 'phrasal': 20690,\n",
       " 'misson': 48167,\n",
       " 'factset': 49383,\n",
       " 'james': 3362,\n",
       " 'ravi': 8672,\n",
       " 'larry': 8590,\n",
       " 'uncaught': 91495,\n",
       " 'cebs': 64623,\n",
       " 'tititcaca': 79355,\n",
       " 'dassault': 23654,\n",
       " 'htc': 3878,\n",
       " 'acquirerequeststate': 56929,\n",
       " 'yext': 54349,\n",
       " 'broomstick': 76765,\n",
       " 'b2b2c': 84345,\n",
       " 'listed': 4889,\n",
       " 'pésterion': 47082,\n",
       " 'avchat': 87028,\n",
       " 'blaspheme': 44627,\n",
       " 'keepassx': 71806,\n",
       " 'parshuram': 26046,\n",
       " '1513': 53434,\n",
       " 'channel': 1255,\n",
       " '617': 19422,\n",
       " 'uplink': 23123,\n",
       " \"f'kd\": 68419,\n",
       " 'psuedaphedrine': 77683,\n",
       " 'harrison': 21598,\n",
       " 'psychiatry': 8827,\n",
       " 'ditched': 18580,\n",
       " 'ovotestis': 60735,\n",
       " 'claustrophobic': 41076,\n",
       " 'offcampus': 23011,\n",
       " 'lanús': 45520,\n",
       " \"moreno's\": 35581,\n",
       " 'dfa': 19203,\n",
       " '1221': 94267,\n",
       " 'otterboxes': 56640,\n",
       " 'unpreventable': 58645,\n",
       " 'sinti': 94775,\n",
       " 'utsav': 72470,\n",
       " 'knowledge': 904,\n",
       " 'difrent': 69350,\n",
       " 'etoos': 22594,\n",
       " 'nullkomanix': 88413,\n",
       " 'pkcs12': 55882,\n",
       " 'camera”': 65731,\n",
       " 'admission': 911,\n",
       " 'unintentionally”': 85584,\n",
       " 'poet': 12993,\n",
       " 'antonie': 64354,\n",
       " '“manger”': 55212,\n",
       " 'baking': 2792,\n",
       " 'images': 1757,\n",
       " 'adverts': 33090,\n",
       " 'mutiny': 25941,\n",
       " 'haprox': 76052,\n",
       " 'neoliberals': 42200,\n",
       " 'mines': 10392,\n",
       " 'mystics': 77590,\n",
       " 'patiala': 24961,\n",
       " 'placememnt': 74668,\n",
       " 'wubbox': 58984,\n",
       " 'omni': 33926,\n",
       " 'msqe': 66103,\n",
       " '08gb': 91456,\n",
       " 'shepard': 30373,\n",
       " 'samyang': 61907,\n",
       " 'hasband': 91165,\n",
       " 'constellation': 18983,\n",
       " 'opternative': 61307,\n",
       " 'slardar': 45638,\n",
       " 'articlesbase': 87308,\n",
       " 'isentropic': 28292,\n",
       " 'chickenpox': 18000,\n",
       " 'p4317q': 59091,\n",
       " 'piercings': 9653,\n",
       " 'inserted': 14361,\n",
       " 'secondlife': 57529,\n",
       " 'illustator': 92479,\n",
       " 'indepth': 69459,\n",
       " 'federalism': 11782,\n",
       " \"'old'\": 92578,\n",
       " 'rambling': 36948,\n",
       " 'rds': 21637,\n",
       " 'descriptions': 11397,\n",
       " 'consequences': 2009,\n",
       " \"fayetteville's\": 34401,\n",
       " 'angels': 5640,\n",
       " 'alim': 73979,\n",
       " \"'chrysanthemums'\": 52188,\n",
       " 'commensalism': 34964,\n",
       " 'flora': 7166,\n",
       " 'synthesis': 11573,\n",
       " 'bloc': 22196,\n",
       " '1755': 13859,\n",
       " 'feeder': 24821,\n",
       " 'nxn': 89394,\n",
       " 'bhuj': 42004,\n",
       " 'artic': 38835,\n",
       " 'lgbtqi': 27352,\n",
       " 'immoral': 8490,\n",
       " 'jenkins': 12622,\n",
       " 'urjent': 76372,\n",
       " 'puberty': 5742,\n",
       " 'emancipated': 35269,\n",
       " 'perfer': 36016,\n",
       " '“spaghetti”': 79021,\n",
       " 'battered': 38307,\n",
       " 'chip–seq': 65167,\n",
       " 'regimen': 13888,\n",
       " 'welder': 20125,\n",
       " \"'pegasus\": 76705,\n",
       " 'thar': 9056,\n",
       " 'scriptwriter': 35626,\n",
       " 'sinuiji': 42027,\n",
       " 'clamp': 54187,\n",
       " 'bloated': 18981,\n",
       " 'clickable': 24776,\n",
       " 'yeoman': 39715,\n",
       " 'lokacart': 32618,\n",
       " 'supplement': 5723,\n",
       " 'resistivity': 16954,\n",
       " 'pavagadh': 94798,\n",
       " 'unbraced': 53020,\n",
       " 'mockery': 29938,\n",
       " 'differentl': 62551,\n",
       " 'millitary': 87886,\n",
       " 'dms': 10799,\n",
       " 'abayas': 62489,\n",
       " 'we’ll': 89260,\n",
       " 'frighten': 87613,\n",
       " 'beethoven': 12258,\n",
       " 'aadvantage': 38980,\n",
       " \"crunchbase's\": 58406,\n",
       " 'world’s': 15708,\n",
       " '9o0gle': 31841,\n",
       " 'lancer': 31689,\n",
       " 'acma': 36402,\n",
       " 'exchange': 1792,\n",
       " 'argue': 6941,\n",
       " 'gilroyis': 73544,\n",
       " 'mpls': 25813,\n",
       " '飛簷走壁': 57889,\n",
       " 'dipping': 28459,\n",
       " 'borgia': 81985,\n",
       " 'rogain': 88549,\n",
       " 'duvets': 94221,\n",
       " 'dialing': 26117,\n",
       " 'hashanah': 70999,\n",
       " 'dreams”': 78608,\n",
       " 'marigaux': 63371,\n",
       " 'cristiano': 4696,\n",
       " 'andaaz': 65809,\n",
       " 'foie': 46687,\n",
       " 'advance': 2956,\n",
       " '193': 83417,\n",
       " 'brightness': 16586,\n",
       " 'sportsdear': 83527,\n",
       " 'yd': 41037,\n",
       " 'financier': 39177,\n",
       " 'jpl': 30694,\n",
       " 'punfound': 52867,\n",
       " 'vsnl': 73351,\n",
       " 'ian': 20194,\n",
       " 'showy': 56846,\n",
       " 'differed': 29275,\n",
       " 'relieves': 42833,\n",
       " 'who’s': 12155,\n",
       " 'doctor’s': 42214,\n",
       " 'ministries': 31028,\n",
       " '535': 15122,\n",
       " 'ccnstitute': 63718,\n",
       " 'pimping': 94430,\n",
       " 'adventure': 6118,\n",
       " 'reciting': 23177,\n",
       " 'riverwalk': 81070,\n",
       " 'anisotropic': 56352,\n",
       " 'manafort': 39868,\n",
       " 'tathagat': 88316,\n",
       " '1055': 54435,\n",
       " 'salmon': 7128,\n",
       " 'bhs': 56093,\n",
       " \"on'\": 32443,\n",
       " 'streakers': 84159,\n",
       " 'organisms': 5469,\n",
       " '500hrs': 51975,\n",
       " 'tullys': 91853,\n",
       " 'mutt': 55067,\n",
       " 'slideshow': 39561,\n",
       " 'floating': 8118,\n",
       " 'امتحان': 39308,\n",
       " 'pas': 2179,\n",
       " 'hoods': 44550,\n",
       " 'hifonics': 49483,\n",
       " 'hasee': 85855,\n",
       " 'yoddha': 84112,\n",
       " 'punishments': 17859,\n",
       " '397': 84781,\n",
       " \"747's\": 85273,\n",
       " 'violin': 4570,\n",
       " 'launching': 5058,\n",
       " 'tlatelolco': 57970,\n",
       " \"'amavasya'\": 74004,\n",
       " 'dyshidrotic': 59213,\n",
       " 'pseudotannins': 72703,\n",
       " 'warmup': 38857,\n",
       " '80kg': 49373,\n",
       " 'zapping': 42527,\n",
       " '2150000': 91627,\n",
       " 'oleksandr': 78227,\n",
       " 'arround': 39438,\n",
       " 'iniesta': 39383,\n",
       " 'accompanied': 23862,\n",
       " 'muslems': 57999,\n",
       " 'tenancy': 40966,\n",
       " 'lhmc': 24350,\n",
       " 'millilitre': 64779,\n",
       " 'troubleshooting': 25688,\n",
       " 'boys': 1326,\n",
       " 'curacao': 35327,\n",
       " 'viewfinders': 42268,\n",
       " 'loras': 52802,\n",
       " \"'zeljko\": 26249,\n",
       " 'masterbuting': 92779,\n",
       " 'invested': 6432,\n",
       " 'yasuo': 80136,\n",
       " 'dhan': 17191,\n",
       " 'mintues': 68130,\n",
       " 'vinci': 6332,\n",
       " '3lack': 58591,\n",
       " 'mastery': 22563,\n",
       " 'zuera': 81094,\n",
       " 'outnumbering': 59270,\n",
       " 'm4': 20788,\n",
       " \"process'\": 61406,\n",
       " 'denominator': 34439,\n",
       " \"goethe's\": 62585,\n",
       " '5hp': 41004,\n",
       " 'akhandbharat': 92659,\n",
       " 'simmons': 41742,\n",
       " 'babolat': 71944,\n",
       " \"combinator's\": 49262,\n",
       " 'hbt': 64806,\n",
       " 'lollichat': 40462,\n",
       " 'rationed': 48349,\n",
       " 'cutrves': 74782,\n",
       " \"''only''\": 82592,\n",
       " 'worthiest': 38342,\n",
       " 'jan': 6534,\n",
       " 'betweed': 64970,\n",
       " 'claude': 26004,\n",
       " \"'slab'\": 47206,\n",
       " 'walt': 7428,\n",
       " 'promised”': 80382,\n",
       " 'grasped': 66646,\n",
       " 'dative': 42232,\n",
       " 'wahhab': 90216,\n",
       " 'controversies': 15845,\n",
       " 'gnip': 56295,\n",
       " 'disribution': 53048,\n",
       " 'nurturing': 13920,\n",
       " 'sledding': 70151,\n",
       " 'bueno': 33038,\n",
       " 'fegree': 65518,\n",
       " '동': 90854,\n",
       " 'rajasthani': 35693,\n",
       " 'subwoofer': 15178,\n",
       " 'continued': 12109,\n",
       " 'slit': 2709,\n",
       " 'glycolysis': 15973,\n",
       " 'sizzix': 49072,\n",
       " 'ibt': 23447,\n",
       " 'walgreens': 24447,\n",
       " 'hostilities': 70853,\n",
       " 'lolaastanova': 68312,\n",
       " 'americo': 68512,\n",
       " 'projectile': 8963,\n",
       " 'lavish': 21119,\n",
       " 'appletv': 49037,\n",
       " 'hazel': 12686,\n",
       " 'semitic': 13624,\n",
       " \"jhunjhunwala's\": 38882,\n",
       " 'slyce': 64613,\n",
       " 'jatts': 49369,\n",
       " \"shari'a\": 71383,\n",
       " 'raymarching': 70623,\n",
       " 'bata': 70175,\n",
       " 'pve': 71134,\n",
       " 'grinder': 14979,\n",
       " 'pizzerias': 54289,\n",
       " 'concocted': 86785,\n",
       " 'diluting': 23334,\n",
       " 'lymphs': 28744,\n",
       " 'fe3c': 73615,\n",
       " 'uprisings': 55209,\n",
       " 'dinnerbox': 67798,\n",
       " 'aniracetam': 93189,\n",
       " 'peening': 88622,\n",
       " \"visitor's\": 41778,\n",
       " 'gay': 760,\n",
       " 'epistemologists': 43233,\n",
       " 'specialized': 12458,\n",
       " 'ioi2017': 94977,\n",
       " \"could'nt\": 70606,\n",
       " '23awg': 51333,\n",
       " 'dürer': 87867,\n",
       " 'haberdasher': 76191,\n",
       " 'nella': 74830,\n",
       " 'figment': 40456,\n",
       " 'jugaad': 28783,\n",
       " 'ilr': 59995,\n",
       " 'swcc': 37534,\n",
       " 'youve': 19367,\n",
       " 'lfino': 81832,\n",
       " 'batao': 47424,\n",
       " 'tray': 21085,\n",
       " 'glover': 82442,\n",
       " 'irobot': 50133,\n",
       " 'wittiness': 83401,\n",
       " 'townsend': 23217,\n",
       " 'predicament': 69693,\n",
       " 'activist': 22357,\n",
       " 'tensioner': 70400,\n",
       " 'tyres': 5796,\n",
       " 'airshow': 70211,\n",
       " 'leafy': 40276,\n",
       " 'minimax': 49180,\n",
       " 'valparaiso': 13231,\n",
       " 'complte': 66141,\n",
       " 'airliners': 12799,\n",
       " 'keimi': 94908,\n",
       " \"foundation's\": 43005,\n",
       " 'frank': 6775,\n",
       " \"'dangal'\": 54581,\n",
       " 'cannibalism': 24661,\n",
       " 'mali': 11957,\n",
       " 'demonitizing': 9981,\n",
       " 'potash': 50936,\n",
       " 'pcsx2': 36814,\n",
       " 'slowed': 18743,\n",
       " 'carpool': 34536,\n",
       " 'studied': 4457,\n",
       " '0x80073cf0': 73251,\n",
       " 'shikh': 92060,\n",
       " 'premam': 33076,\n",
       " 'takeovers': 74422,\n",
       " \"epmd's\": 89571,\n",
       " 'rationalistic': 64730,\n",
       " 'tangled': 20957,\n",
       " 'kering': 76469,\n",
       " 'experimentallt': 61506,\n",
       " 'nrsc': 41239,\n",
       " 'vertically': 11002,\n",
       " 'slk': 65784,\n",
       " '1293lz': 65747,\n",
       " 'cottari': 90664,\n",
       " 'starburst': 34263,\n",
       " 'vaginal': 6594,\n",
       " \"'main\": 53215,\n",
       " 'phrased': 33960,\n",
       " 'naïve': 54402,\n",
       " 'nephilim': 36563,\n",
       " 'sabf': 94841,\n",
       " 'alizeh': 59652,\n",
       " 'pouting': 74013,\n",
       " 'asimov': 24048,\n",
       " 'populated': 8631,\n",
       " 'numbet': 60820,\n",
       " 'sitrans': 83107,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = 1500)  #only 1500 words are taken in consideration for our model\n",
    "#Fitting on vocabulary coming out of both train and test.\n",
    "tokenizer.fit_on_texts(np.concatenate((train.question1.astype(str), train.question2.astype(str)), axis=0))\n",
    "\n",
    "sequences_train_q1 = tokenizer.texts_to_sequences(train.question1.astype(str))\n",
    "sequences_train_q2 = tokenizer.texts_to_sequences(train.question2.astype(str))\n",
    "\n",
    "\n",
    "sequences_test_q1 = tokenizer.texts_to_sequences(test.question1.astype(str))\n",
    "sequences_test_q2 = tokenizer.texts_to_sequences(test.question2.astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95595"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train_q1_padded = pad_sequences(sequences_train_q1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "sequences_train_q2_padded = pad_sequences(sequences_train_q2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "sequences_test_q1_padded = pad_sequences(sequences_test_q1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "sequences_test_q2_padded = pad_sequences(sequences_test_q2, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_matrix = np.zeros((nb_words+1, EMBEDDING_DIM))\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('D:\\\\coviam bangalore\\\\glove.6B.50d.txt',encoding=\"utf-8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]       #gives the word for which vector is given\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_train_q1_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "\n",
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "features  = Input(shape=(3,))\n",
    "\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=True)(question1)\n",
    "\n",
    "#q1 = Bidirectional(LSTM(30), merge_mode=\"sum\")(q1)\n",
    "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
    "\n",
    "q1_max = Lambda(lambda x: K.max(x, axis=1), output_shape=(MAX_SEQUENCE_LENGTH, ))(q1)\n",
    "q1_max_1 = Lambda(lambda x: K.max(x, axis=2), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "q1_sum = Lambda(lambda x: K.sum(x, axis=1), output_shape=(MAX_SEQUENCE_LENGTH, ))(q1)\n",
    "q1_sum_1 = Lambda(lambda x: K.sum(x, axis=2), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=True)(question2)\n",
    "\n",
    "#q2 = Bidirectional(LSTM(30), merge_mode=\"sum\")(q2)\n",
    "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
    "\n",
    "q2_max = Lambda(lambda x: K.max(x, axis=1), output_shape=(MAX_SEQUENCE_LENGTH, ))(q2)\n",
    "q2_max_1 = Lambda(lambda x: K.sum(x, axis=2), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "q2_sum = Lambda(lambda x: K.sum(x, axis=1), output_shape=(MAX_SEQUENCE_LENGTH, ))(q2)\n",
    "q2_sum_1 = Lambda(lambda x: K.sum(x, axis=2), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "#q2 = Flatten()(q2)\n",
    "\n",
    "##functional keras code instead of the normal sequential code\n",
    "merged = concatenate([q1_max,q2_max,q1_sum,q2_sum,q1_sum_1,q2_sum_1,q1_max_1,q2_max_1,features])\n",
    "merged = Dense(300, activation='relu')(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(100, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(100, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(50, activation='relu')(merged)\n",
    "merged = Dropout(0.1)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model_1 = Model(inputs=[question1,question2,features], outputs=is_duplicate)\n",
    "auc_roc = as_keras_metric(tf.metrics.auc)\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc_roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 50)       250050      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 50)       250050      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 20, 50)       2550        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 20, 50)       2550        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 20)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 20)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 20)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 20)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 283)          0           lambda_1[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          85200       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          30100       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          10100       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100)          400         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 50)           5050        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 50)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 50)           200         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            51          batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 637,901\n",
      "Trainable params: 636,801\n",
      "Non-trainable params: 1,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n",
    "sequences_train_q1_padded.shape\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'ann_visualizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7bd55b1f6729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mann_visualizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#ann_viz(model, view=True, filename=”network_1.gv”, title=”MyNeuralNetwork”)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'ann_visualizer'"
     ]
    }
   ],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "#ann_viz(model, view=True, filename=”network_1.gv”, title=”MyNeuralNetwork”)\n",
    "ann_viz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363858 samples, validate on 40429 samples\n",
      "Epoch 1/20\n",
      "363858/363858 [==============================] - 340s 935us/step - loss: 0.5233 - auc: 0.7104 - val_loss: 0.4459 - val_auc: 0.7952\n",
      "Epoch 2/20\n",
      "363858/363858 [==============================] - 346s 950us/step - loss: 0.4659 - auc: 0.8116 - val_loss: 0.4384 - val_auc: 0.8214\n",
      "Epoch 3/20\n",
      "363858/363858 [==============================] - 340s 936us/step - loss: 0.4572 - auc: 0.8272 - val_loss: 0.4303 - val_auc: 0.8315\n",
      "Epoch 4/20\n",
      "363858/363858 [==============================] - 342s 939us/step - loss: 0.4519 - auc: 0.8347 - val_loss: 0.4298 - val_auc: 0.8373 loss: 0.4519 - a\n",
      "Epoch 5/20\n",
      "363858/363858 [==============================] - 341s 938us/step - loss: 0.4473 - auc: 0.8395 - val_loss: 0.4232 - val_auc: 0.8414\n",
      "Epoch 6/20\n",
      "363858/363858 [==============================] - 343s 943us/step - loss: 0.4445 - auc: 0.8430 - val_loss: 0.4367 - val_auc: 0.8443\n",
      "Epoch 7/20\n",
      "363858/363858 [==============================] - 342s 940us/step - loss: 0.4427 - auc: 0.8456 - val_loss: 0.4285 - val_auc: 0.8466\n",
      "Epoch 8/20\n",
      "363858/363858 [==============================] - 347s 954us/step - loss: 0.4404 - auc: 0.8476 - val_loss: 0.4291 - val_auc: 0.8485\n",
      "Epoch 9/20\n",
      "363858/363858 [==============================] - 349s 959us/step - loss: 0.4392 - auc: 0.8493 - val_loss: 0.4217 - val_auc: 0.8501\n",
      "Epoch 10/20\n",
      "363858/363858 [==============================] - 348s 957us/step - loss: 0.4381 - auc: 0.8507 - val_loss: 0.4319 - val_auc: 0.8514\n",
      "Epoch 11/20\n",
      "363858/363858 [==============================] - 348s 955us/step - loss: 0.4378 - auc: 0.8519 - val_loss: 0.4230 - val_auc: 0.8525\n",
      "Epoch 12/20\n",
      "363858/363858 [==============================] - 347s 954us/step - loss: 0.4371 - auc: 0.8530 - val_loss: 0.4202 - val_auc: 0.8534\n",
      "Epoch 13/20\n",
      "248064/363858 [===================>..........] - ETA: 1:53 - loss: 0.4356 - auc: 0.8538- ETA: 2 - ETA: 2:07 - loss: 0.4356 - a - ETA: 1:5"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-bf78a1ddd0d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                    initial_epoch = 0)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_1.fit([sequences_train_q1_padded, sequences_train_q2_padded,train_features],\n",
    "                    train.is_duplicate,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,callbacks=[tbCallBack],\n",
    "                   initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363858 samples, validate on 40429 samples\n",
      "Epoch 19/20\n",
      "363858/363858 [==============================] - 288s 791us/step - loss: 0.4452 - auc: 0.8501 - val_loss: 0.4332 - val_auc: 0.8503\n",
      "Epoch 20/20\n",
      "363858/363858 [==============================] - 286s 785us/step - loss: 0.4442 - auc: 0.8505 - val_loss: 0.4354 - val_auc: 0.8507\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit([sequences_train_q1_padded, sequences_train_q2_padded,train_features],\n",
    "                    train.is_duplicate,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,callbacks=[tbCallBack],\n",
    "                   initial_epoch = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([sequences_test_q1_padded, sequences_test_q2_padded,test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_and_confusion_report(test.is_duplicate,y_pred,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"D:\\\\coviam bangalore\\\\all\\\\test.csv\")\n",
    "test_data=test_data.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563475, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test_data_q1 = tokenizer.texts_to_sequences(test_data.question1.astype(str))\n",
    "sequences_test_data_q2 = tokenizer.texts_to_sequences(test_data.question2.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test_data_q1_padded = pad_sequences(sequences_test_data_q1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "sequences_test_data_q2_padded = pad_sequences(sequences_test_data_q2, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-2d6bff3d539d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msequences_test_data_q2_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences_test_data_q2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cosine_similarity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"char_match_count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmatch_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"word_match_count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmatch_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_data_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'char_match_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'word_match_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cosine_similarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[1;32m-> 6004\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mconstructor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         return (constructor(arr, index=self.columns, name=name)\n\u001b[1;32m--> 367\u001b[1;33m                 for i, (arr, name) in enumerate(zip(self.values,\n\u001b[0m\u001b[0;32m    368\u001b[0m                                                     self.index)))\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    274\u001b[0m                                        raise_cast_failure=True)\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[0;32m   4675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4676\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4677\u001b[1;33m             \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4679\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   3197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3199\u001b[1;33m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3201\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetimetz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_block_type\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m   3174\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetimetz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3175\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3176\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mis_datetimetz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3177\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_datetimetz\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# It seems like a repeat of is_datetime64tz_dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     return ((isinstance(arr, ABCDatetimeIndex) and\n\u001b[0m\u001b[0;32m    269\u001b[0m              getattr(arr, 'tz', None) is not None) or\n\u001b[0;32m    270\u001b[0m             is_datetime64tz_dtype(arr))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "test_data[\"cosine_similarity\"]=test_data.apply(lambda x: get_cosine(text_to_vector(x[\"question1\"]),text_to_vector(x[\"question2\"])),axis=1)\n",
    "test_data[\"char_match_count\"]= test_data.apply(lambda row: match_count(row[\"question1\"],row[\"question2\"]),axis=1)\n",
    "test_data[\"word_match_count\"] = test_data.apply(lambda row: match_count(row[\"question1\"].split(),row[\"question2\"].split()),axis=1)\n",
    "test_data_features=test_data[['char_match_count','word_match_count','cosine_similarity']]\n",
    "print(\"features completed\")\n",
    "y_pred = model_1.predict([sequences_test_data_q1_padded, sequences_test_data_q2_padded,test_data_features])\n",
    "test_data[\"is_duplicate\"]=y_pred\n",
    "output=test_data.drop(['cosine_similarity', 'char_match_count','word_match_count'], axis=1)\n",
    "#output.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"is_duplicate\"]=output[\"is_duplicate\"].apply(lambda x: 0 if x<0.5 else 1)\n",
    "df=output[[\"test_id\",\"is_duplicate\"]]\n",
    "df.to_csv(\"D:\\\\coviam bangalore\\\\all\\\\submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[379205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_colwidth = 200\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.is_duplicate.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sort_values(ascending=False,by = \"is_duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
